# ğŸ˜„ Emotion Detection Using MobileNetV2 on FER-2013 Dataset

This project builds and fine-tunes a **MobileNetV2** model for facial emotion recognition using the **FER-2013** dataset. The model is trained to classify emotions into 7 categories and is evaluated using accuracy and loss plots.

---

## ğŸ“Œ Overview

- ğŸ“¦ **Model:** MobileNetV2 (transfer learning)
- ğŸ§  **Task:** Facial Emotion Recognition
- ğŸ–¼ï¸ **Dataset:** FER-2013 (Kaggle)
- ğŸ§ª **Emotions Detected:** Angry, Disgust, Fear, Happy, Sad, Surprise, Neutral
- ğŸ“ˆ **Metrics Tracked:** Accuracy, Loss, Confusion Matrix

---

## ğŸ“ Project Structure

emotion-detection-fer13-mobilenetv2/
â”‚
â”œâ”€â”€ Emotion_Detection_Using_MobileNetV2.ipynb # Training & evaluation notebook
â”œâ”€â”€ emotion_model.keras # Trained model saved in Keras format
â”œâ”€â”€ README.md # Project documentation
â”œâ”€â”€ requirements.txt # Required dependencies
â””â”€â”€ fer2013.csv # Dataset (if locally included)

---

## ğŸ¯ Dataset

- **Name:** FER-2013  
- **Source:** [Kaggle FER-2013 Dataset](https://www.kaggle.com/datasets/msambare/fer2013)
- **Details:** 48x48 grayscale facial emotion images  
- **Classes:**  
  `['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']`

---

## ğŸ§  Model Architecture

- **Base Model:** MobileNetV2 (with pretrained ImageNet weights)
- **Input Shape:** (160, 160, 3)
- **Training Approach:** Fine-tune top layers of MobileNetV2
- **Output Layer:** Dense layer with softmax activation for 7 classes

---

## ğŸ“Š Evaluation Metrics

- Training Accuracy
- Validation Accuracy
- Training Loss
- Validation Loss

---

## ğŸ“ˆ Sample Plots

Plots are automatically generated in the notebook:

- ğŸ“‰ **Accuracy vs Epoch**
- ğŸ“‰ **Loss vs Epoch**

---

## ğŸš€ How to Run

### 1. Clone the Repository

```bash
git clone https://github.com/RishitSaxena55/Emotion-Detection-FER 13-MobileNetV2.git
cd Emotion-Detection-FER 13-MobileNetV2
